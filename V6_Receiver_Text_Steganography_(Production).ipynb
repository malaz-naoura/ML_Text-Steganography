{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnmOyNkdaM9Z"
      },
      "source": [
        "# 0) Download Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zTXqlm2nQ5jg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce9bd1c-0004-438b-8ead-77593d88c02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import transformers\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "from math import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Initialize parameters"
      ],
      "metadata": {
        "id": "Yk9sagx-pJxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG=False\n",
        "\n",
        "\n",
        "senderGeneratedText=\"حققت تونس الدولة المضيفة تعادلا الإيجابي الاثنين أمس الجمعة إلى صفر صفرا مع اليونان الأوروبية الجنسية الأمريكية الشرقية مقابل اليابان المصرية الرسمية الجنسية الداخلية الألمانية\"\n",
        "senderGeneratedText=\"أعلن الريس على عن حياته قريبا السبت الجمعة الماضي إلى حين تاريخ النهاية مع العدالة المتحدة الجمعة قبل الغد وبعد الأربعاء هذا هذان هذانث هذانثة هذانثةه هو\"\n",
        "\n",
        "\n",
        "from enum import Enum\n",
        "class SourceCoding(Enum):\n",
        "    HUFFMAN = 1\n",
        "    BINARY  = 3\n",
        "\n",
        "class TextGenerationLang(Enum):\n",
        "    Arabic  = 1\n",
        "\n",
        "class ModelName(Enum):\n",
        "    Roberta = 7\n",
        "\n",
        "class StegoPriority(Enum):\n",
        "    Capacity=1\n",
        "    Efficiency=2\n",
        "    Imperceptibility=3\n",
        "\n",
        "top_k=32\n",
        "sourceCodingType=SourceCoding.HUFFMAN\n",
        "TextGenerationLang=TextGenerationLang.Arabic\n",
        "choosenModel=ModelName.Roberta\n",
        "choosenStegoPriority=StegoPriority.Capacity\n",
        "\n",
        "# Discard the first ? words because they were added to control the context and do not have any data hidden inside them.\n",
        "# This is a constant number that should match between sender and receiver before lunch. (Same as length of senderGeneratedText variable in Sender)\n",
        "numberOfContextWordAdded=4"
      ],
      "metadata": {
        "id": "911LVXrhpUHr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM-ADRkYbQiv"
      },
      "source": [
        "# 3) Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You Model"
      ],
      "metadata": {
        "id": "7qZcKk0gK6Q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if choosenModel==ModelName.Roberta:\n",
        "  from transformers import pipeline,TFAutoModelForMaskedLM,TFBertForMaskedLM\n",
        "  from transformers import AutoTokenizer\n",
        "\n",
        "  # For example, this model is not good; you should use your trained model instead.\n",
        "  checkpoint=\"xlm-roberta-base\"\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "  model_name=checkpoint\n",
        "\n",
        "  def fillArabicMaskWithRoberta(text,top_k=30):\n",
        "    text=text+\" <mask>\"\n",
        "    model = pipeline(task =\"fill-mask\",model=model_name,tokenizer=tokenizer,top_k =top_k,device=0)\n",
        "    return model(text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "48uDaYFWLJqL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "48bd83221de04ff8b445ed2670d2ea21",
            "85188d8f127241e1abf260a136076858",
            "3f99f15e8e7243be9a0c3989a33173dd",
            "57654d19e2454e7d860c42203f485c5d",
            "b1bc2e8a8deb4686a5dfe955778bf232",
            "ba06041d6ebf4f638019abfa1f720cd1",
            "14676e02319b438a9e3996cea16fb8e8",
            "3b28e1593f6b4331ac53fb117bba1bc8",
            "819108abc84d4166b6865edb17b34077",
            "35fd6dcaeab14a0d886ae74b6cfb8a1a",
            "44525d3313b84f19ba56bf89cabd7df9",
            "dcf4db08072840b5bc805c26f049ea8a",
            "da5fae56e2b94e91a9a9d2e95c97b5f5",
            "c8b1e0d2a5af4314813c7bf60e68945a",
            "d539deca225d47a0aaaff4ec03acfba8",
            "857fdaf6c88b48bdade3bef37cdfd93e",
            "3e649106e4e74bc5b2597ce24a3121d7",
            "355e898469d646758956dc817bd3b48c",
            "f07a1844e2504f4c86694219fc2803d8",
            "f5d81838ae414a5fb5ff402fb51b8a7d",
            "6e3d3cf80a2b4e78a7ec6eea743e55d9",
            "ae1580be847849d5bf233753255c5d60",
            "8f6c40f94fca4ae980e0923502033058",
            "86a2fe7fcdc74c28b36593b2c6dabf1b",
            "0d6fc4428ea04978ada39f2da16c5a55",
            "5c015956be764fb5902dbfe7a4d27d6c",
            "11f9d3de11da4b38845b06710eaada0f",
            "8cf6b7a5604d4f33afbfd44266179bc9",
            "11fb9e8e726146658e192e4214a916e0",
            "0a08ec21c6474a05ba182c5f5065f693",
            "6c7252fdc0224ca9aef92cf3d66cdee9",
            "d3bac57d47d9464b8e58b193f345cb60",
            "b8fd9ec7c49c47e1820d44c473ab51d0"
          ]
        },
        "outputId": "297552dd-dfc3-4655-c8a1-fd840354b86e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48bd83221de04ff8b445ed2670d2ea21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcf4db08072840b5bc805c26f049ea8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f6c40f94fca4ae980e0923502033058"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGdal5F1mnSV"
      },
      "source": [
        "# 4) Enconding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uHJ6-1cmsyM"
      },
      "source": [
        "## 1) Huffman Coding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R-dG1Ulvm0Wl"
      },
      "outputs": [],
      "source": [
        "# A Huffman Tree Node\n",
        "class Node:\n",
        "    def __init__(self, prob, symbol, left=None, right=None):\n",
        "        # probability of symbol\n",
        "        self.prob = prob\n",
        "\n",
        "        # symbol\n",
        "        self.symbol = symbol\n",
        "\n",
        "        # left node\n",
        "        self.left = left\n",
        "\n",
        "        # right node\n",
        "        self.right = right\n",
        "\n",
        "        # tree direction (0/1)\n",
        "        self.code = ''\n",
        "\n",
        "\"\"\" A helper function to print the codes of symbols by traveling Huffman Tree\"\"\"\n",
        "codes = dict()\n",
        "\n",
        "def Calculate_Codes(node, val=''):\n",
        "    # huffman code for current node\n",
        "    newVal = val + str(node.code)\n",
        "\n",
        "    if(node.left):\n",
        "        Calculate_Codes(node.left, newVal)\n",
        "    if(node.right):\n",
        "        Calculate_Codes(node.right, newVal)\n",
        "\n",
        "    if(not node.left and not node.right):\n",
        "        codes[node.symbol] = newVal\n",
        "\n",
        "    return codes\n",
        "\n",
        "\"\"\" A helper function to calculate the probabilities of symbols in given data\"\"\"\n",
        "def Calculate_Probability(data):\n",
        "    symbols = dict()\n",
        "    for element in data:\n",
        "        if symbols.get(element) == None:\n",
        "            symbols[element] = 1\n",
        "        else:\n",
        "            symbols[element] += 1\n",
        "    return symbols\n",
        "\n",
        "\"\"\" A helper function to obtain the encoded output\"\"\"\n",
        "def Output_Encoded(data, coding):\n",
        "    encoding_output = []\n",
        "    for c in data:\n",
        "      #  print(coding[c], end = '')\n",
        "        encoding_output.append(coding[c])\n",
        "\n",
        "    string = ''.join([str(item) for item in encoding_output])\n",
        "    return string\n",
        "\n",
        "\"\"\" A helper function to calculate the space difference between compressed and non compressed data\"\"\"\n",
        "def Total_Gain(data, coding):\n",
        "    before_compression = len(data) * 8 # total bit space to stor the data before compression\n",
        "    after_compression = 0\n",
        "    symbols = coding.keys()\n",
        "    for symbol in symbols:\n",
        "        count = data.count(symbol)\n",
        "        after_compression += count * len(coding[symbol]) #calculate how many bit is required for that symbol in total\n",
        "    if DEBUG:\n",
        "      print(\"Space usage before compression (in bits):\", before_compression)\n",
        "      print(\"Space usage after compression (in bits):\",  after_compression)\n",
        "\n",
        "def Huffman_Encoding(data):\n",
        "    symbol_with_probs = Calculate_Probability(data)\n",
        "    symbols = symbol_with_probs.keys()\n",
        "    probabilities = symbol_with_probs.values()\n",
        "    if DEBUG:\n",
        "      print(\"symbols: \", symbols)\n",
        "      print(\"probabilities: \", probabilities)\n",
        "\n",
        "\n",
        "    nodes = []\n",
        "    # converting symbols and probabilities into huffman tree nodes\n",
        "    for symbol in symbols:\n",
        "        nodes.append(Node(symbol_with_probs.get(symbol), symbol))\n",
        "\n",
        "    while len(nodes) > 1:\n",
        "        # sort all the nodes in ascending order based on their probability\n",
        "        nodes = sorted(nodes, key=lambda x: x.prob)\n",
        "        # for node in nodes:\n",
        "        #      print(node.symbol, node.prob)\n",
        "\n",
        "        # pick 2 smallest nodes\n",
        "        right = nodes[0]\n",
        "        left = nodes[1]\n",
        "\n",
        "        left.code = 0\n",
        "        right.code = 1\n",
        "\n",
        "        # combine the 2 smallest nodes to create new node\n",
        "        newNode = Node(left.prob+right.prob, left.symbol+right.symbol, left, right)\n",
        "\n",
        "        nodes.remove(left)\n",
        "        nodes.remove(right)\n",
        "        nodes.append(newNode)\n",
        "\n",
        "    huffman_encoding = Calculate_Codes(nodes[0])\n",
        "    if DEBUG:\n",
        "      print(\"symbols with codes\", huffman_encoding)\n",
        "\n",
        "    Total_Gain(data, huffman_encoding)\n",
        "    encoded_output = Output_Encoded(data,huffman_encoding)\n",
        "    return encoded_output, nodes[0],huffman_encoding\n",
        "\n",
        "\n",
        "def Huffman_Decoding(encoded_data, huffman_tree,wordSplit=False):\n",
        "    tree_head = huffman_tree\n",
        "    decoded_output = []\n",
        "    for x in encoded_data:\n",
        "        if x == '1':\n",
        "            huffman_tree = huffman_tree.right\n",
        "        elif x == '0':\n",
        "            huffman_tree = huffman_tree.left\n",
        "        try:\n",
        "            if huffman_tree.left.symbol == None and huffman_tree.right.symbol == None:\n",
        "                pass\n",
        "        except AttributeError:\n",
        "            decoded_output.append(huffman_tree.symbol)\n",
        "            huffman_tree = tree_head\n",
        "\n",
        "    delimiter= ' ' if wordSplit else ''\n",
        "    string = delimiter.join([str(item) for item in decoded_output])\n",
        "    return string\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def encodeByHuffman(data,wordSplit=False):\n",
        "  data=data.strip()\n",
        "  if wordSplit:\n",
        "    data=data.split(' ')\n",
        "\n",
        "  global codes\n",
        "  codes=dict()\n",
        "  encoding, tree,mapping = Huffman_Encoding(data)\n",
        "  return (encoding,tree,mapping)\n",
        "\n",
        "def decodeByHuffman(encoding,tree,wordSplit=False):\n",
        "  return Huffman_Decoding(encoding,tree,wordSplit)\n",
        "\n"
      ],
      "metadata": {
        "id": "UiochXCooUeS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Binary Tree Coding"
      ],
      "metadata": {
        "id": "oeeACuajn_75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buildBinaryTreeCoding(words,currCode=''):\n",
        "\n",
        "  l=len(words)\n",
        "\n",
        "  if log2(l)!= log2(pow(2,int(log2(l)))):\n",
        "    print('The Length Is Not Power Of 2')\n",
        "    return None\n",
        "\n",
        "  if l==1:\n",
        "    return [currCode]\n",
        "    # return [(words[0],currCode)]\n",
        "\n",
        "  mid=int(l/2)\n",
        "  a=buildBinaryTreeCoding(words[:mid],currCode+'0')\n",
        "  b=buildBinaryTreeCoding(words[mid:],currCode+'1')\n",
        "\n",
        "  return a+b\n",
        "\n",
        "def binaryTreeEncoding(words):\n",
        "  l=len(words)\n",
        "  leafNb=int(pow(2,int(log2(l))))\n",
        "  restToCeilLog=int(pow(2,ceil(log2(l))))-leafNb\n",
        "  words=words+['NO_TOKEN_'+str(i) for i in range(1,restToCeilLog)]\n",
        "  if DEBUG==True:\n",
        "    print(len(words))\n",
        "    print(words)\n",
        "  wordsCode=buildBinaryTreeCoding(words)\n",
        "  mapWordToCode= {k:v  for k,v in zip(words,wordsCode) }\n",
        "  encoding=''.join(list(map(lambda x:mapWordToCode[x],words)))\n",
        "  return encoding,mapWordToCode\n",
        "\n"
      ],
      "metadata": {
        "id": "V0ZlLLExoXK2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encodeByBinaryTree(data,wordSplit=False):\n",
        "  data=data.strip()\n",
        "  if wordSplit:\n",
        "    data=data.split(' ')\n",
        "  else:\n",
        "    data=list(set(data))\n",
        "\n",
        "  encoding,mapping = binaryTreeEncoding(data)\n",
        "  return (encoding,mapping)\n"
      ],
      "metadata": {
        "id": "JtOXXvpqocaq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ImOw1HwyGS3"
      },
      "source": [
        "# OO ) Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAfPThrO-1to"
      },
      "source": [
        "### Common Functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fillMask(generatedText,top_k=top_k):\n",
        "  top_k=top_k*2\n",
        "  masks=[]\n",
        "  if choosenModel==ModelName.Roberta:\n",
        "    masks=fillArabicMaskWithRoberta(generatedText,top_k=top_k)\n",
        "  return masks"
      ],
      "metadata": {
        "id": "KvareR4TU819"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ax2HIKli-5lK"
      },
      "outputs": [],
      "source": [
        "def generateNextMaskedWord(generatedText,wordIdx,sourceCodingType,top_kth):\n",
        "  tok_k=top_kth\n",
        "\n",
        "  if TextGenerationLang==TextGenerationLang.Arabic:\n",
        "    substitution=r'[^\\u0620-\\u064a ]*'\n",
        "  elif TextGenerationLang==TextGenerationLang.English:\n",
        "    substitution=r'[^a-zA-Z ]*'\n",
        "\n",
        "  masks=fillMask(generatedText,top_k=top_k)\n",
        "  masks=list(map(lambda ele: re.sub(substitution, '', ele[\"sequence\"].split(\" \")[-1]),masks))\n",
        "\n",
        "  if DEBUG==True:\n",
        "    print(\"Masks: \",masks)\n",
        "\n",
        "  lastWord=''\n",
        "  if DEBUG==True:\n",
        "    print(\"last element of genereted text : \" )\n",
        "    print(generatedText.split(\" \"))\n",
        "\n",
        "  if len(generatedText.split(\" \"))>0:\n",
        "    if DEBUG==True:\n",
        "      print(\"last element of genereted text : \"+ generatedText.split(\" \")[-1])\n",
        "    lastWord=generatedText.split(\" \")[-1]\n",
        "  masks=list(filter(lambda ele: (ele!='' and len(ele)!=1 and ele!=lastWord) ,masks))\n",
        "  masks=masks[0:max(len(masks),int(top_k/2))]\n",
        "\n",
        "  encoding=mapWordToCode=None\n",
        "  if sourceCodingType==SourceCoding.HUFFMAN:\n",
        "    masks=' '.join(masks)\n",
        "    encoding,_,mapWordToCode=encodeByHuffman(masks,True)\n",
        "  elif sourceCodingType==SourceCoding.BINARY:\n",
        "    l=len(masks)\n",
        "    leafNb=int(pow(2,int(log2(l))))\n",
        "    if DEBUG==True:\n",
        "      print('leafNb: ',leafNb)\n",
        "    masks=masks[:leafNb]\n",
        "    # if DEBUG==True:\n",
        "    print(\"edit len mask : \",len(masks))\n",
        "    masks=' '.join(masks)\n",
        "    encoding,mapWordToCode=encodeByBinaryTree(masks,True)\n",
        "\n",
        "  mapCodeToWord=dict(map(reversed, mapWordToCode.items()))\n",
        "  return (encoding,mapWordToCode,mapCodeToWord)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcLwfMSUWM0B"
      },
      "source": [
        "## Receiver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_aDPzRbkKUp"
      },
      "source": [
        "### Masked Generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "senderGeneratedTextList=senderGeneratedText.split(\" \")\n",
        "\n",
        "receiverGeneratedText=senderGeneratedTextList[:numberOfContextWordAdded]\n",
        "senderGeneratedTextList=senderGeneratedTextList[numberOfContextWordAdded:]\n",
        "\n",
        "if DEBUG==True:\n",
        "  print(receiverGeneratedText)\n",
        "  print(senderGeneratedTextList)"
      ],
      "metadata": {
        "id": "lu8zG0B2P1IN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FYEs9psIWMB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ef7d50-d032-42f7-ee35-b6e3f1f2f1d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1010000010000011001001001111110100110010011111110100000111011010100110001111010000011101101001010100110001\n"
          ]
        }
      ],
      "source": [
        "if DEBUG==True:\n",
        "  print(senderGeneratedText)\n",
        "END_TOKEN_CODE=\"0\"*8\n",
        "\n",
        "senderGeneratedTextList=senderGeneratedText.split(\" \")\n",
        "receiverGeneratedText=' '.join(senderGeneratedTextList[:numberOfContextWordAdded])\n",
        "senderGeneratedTextList=senderGeneratedTextList[numberOfContextWordAdded:]\n",
        "\n",
        "receiverEncodingSecretMessage=\"\"\n",
        "\n",
        "for i in range(0,len(senderGeneratedTextList)):\n",
        "  encoding,mapWordToCode,mapCodeToWord=generateNextMaskedWord(receiverGeneratedText,i,sourceCodingType,top_k)\n",
        "  if DEBUG==True:\n",
        "    print(mapCodeToWord)\n",
        "  currSenderWord=senderGeneratedTextList[i]\n",
        "  currSenderCode=mapWordToCode.get(currSenderWord)\n",
        "\n",
        "  if DEBUG==True:\n",
        "    print(currSenderWord)\n",
        "    print(currSenderCode)\n",
        "\n",
        "  if len(receiverGeneratedText)!=0:\n",
        "    receiverGeneratedText=receiverGeneratedText+\" \"\n",
        "  receiverGeneratedText=receiverGeneratedText+currSenderWord\n",
        "  receiverEncodingSecretMessage=receiverEncodingSecretMessage+currSenderCode\n",
        "\n",
        "if DEBUG==True:\n",
        "  print(\"receiverGeneratedText : \"+receiverGeneratedText)\n",
        "  print(\"length of secret message enconding : \"+str(len(receiverEncodingSecretMessage)))\n",
        "  print(receiverEncodingSecretMessage)\n",
        "\n",
        "\n",
        "\n",
        "receiverEncodingSecretMessage=receiverEncodingSecretMessage[::-1]\n",
        "\n",
        "x = re.search(END_TOKEN_CODE, receiverEncodingSecretMessage)\n",
        "\n",
        "receiverEncodingSecretMessage=receiverEncodingSecretMessage[x.end():]\n",
        "receiverEncodingSecretMessage=receiverEncodingSecretMessage[::-1]\n",
        "\n",
        "if DEBUG==True:\n",
        "  print(receiverEncodingSecretMessage)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encodingSecretMessage=receiverEncodingSecretMessage\n",
        "decodingSecretMessage=\"\"\n",
        "mapCodeToLetter={'0000': 'ل', '000100': 'ص', '0001010': 'ج', '0001011': 'ز', '000110': 'أ', '000111': 'ف', '001000': 'ك', '00100100': 'إ', '0010010100': 'ظ', '0010010101': 'آ', '001001011': 'ء', '0010011': 'ش', '00101': 'ب', '00110': 'و', '0011100': 'ح', '0011101': 'خ', '001111': 'د', '01000': 'م', '01001': 'ع', '0101000': 'ط', '0101001': 'ذ', '0101010': 'ى', '0101011': 'ض', '01011': 'ر', '0110': 'ي', '011100': 'ة', '011101': 'س', '01111': 'ت', '100000': 'ق', '10000100': 'ث', '10000101': 'غ', '1000011': 'ئ', '10001': 'ه', '1001': 'ن', '101': 'ا', '11': ' '}\n",
        "\n",
        "encodingSecretMessageLength=len(encodingSecretMessage)\n",
        "while len(encodingSecretMessage)!=0:\n",
        "  for i in range(0,encodingSecretMessageLength):\n",
        "    senderCurrEncodingMatchTest=encodingSecretMessage[0:encodingSecretMessageLength-i]\n",
        "    if mapCodeToLetter.get(senderCurrEncodingMatchTest)==None:\n",
        "      continue\n",
        "    senderChoosenLetter=mapCodeToLetter.get(senderCurrEncodingMatchTest)\n",
        "\n",
        "    decodingSecretMessage=decodingSecretMessage+senderChoosenLetter\n",
        "    encodingSecretMessage=encodingSecretMessage[encodingSecretMessageLength-i:]\n",
        "    break\n",
        "\n",
        "\n",
        "print(decodingSecretMessage)\n"
      ],
      "metadata": {
        "id": "TsFhTI9sT3JO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b79f8b39-a197-41fb-b0cc-6a2af9ce1d0d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "الموعد عند الساعه السابعه\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48bd83221de04ff8b445ed2670d2ea21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85188d8f127241e1abf260a136076858",
              "IPY_MODEL_3f99f15e8e7243be9a0c3989a33173dd",
              "IPY_MODEL_57654d19e2454e7d860c42203f485c5d"
            ],
            "layout": "IPY_MODEL_b1bc2e8a8deb4686a5dfe955778bf232"
          }
        },
        "85188d8f127241e1abf260a136076858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba06041d6ebf4f638019abfa1f720cd1",
            "placeholder": "​",
            "style": "IPY_MODEL_14676e02319b438a9e3996cea16fb8e8",
            "value": "config.json: 100%"
          }
        },
        "3f99f15e8e7243be9a0c3989a33173dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b28e1593f6b4331ac53fb117bba1bc8",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_819108abc84d4166b6865edb17b34077",
            "value": 615
          }
        },
        "57654d19e2454e7d860c42203f485c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35fd6dcaeab14a0d886ae74b6cfb8a1a",
            "placeholder": "​",
            "style": "IPY_MODEL_44525d3313b84f19ba56bf89cabd7df9",
            "value": " 615/615 [00:00&lt;00:00, 38.1kB/s]"
          }
        },
        "b1bc2e8a8deb4686a5dfe955778bf232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba06041d6ebf4f638019abfa1f720cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14676e02319b438a9e3996cea16fb8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b28e1593f6b4331ac53fb117bba1bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819108abc84d4166b6865edb17b34077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35fd6dcaeab14a0d886ae74b6cfb8a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44525d3313b84f19ba56bf89cabd7df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcf4db08072840b5bc805c26f049ea8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da5fae56e2b94e91a9a9d2e95c97b5f5",
              "IPY_MODEL_c8b1e0d2a5af4314813c7bf60e68945a",
              "IPY_MODEL_d539deca225d47a0aaaff4ec03acfba8"
            ],
            "layout": "IPY_MODEL_857fdaf6c88b48bdade3bef37cdfd93e"
          }
        },
        "da5fae56e2b94e91a9a9d2e95c97b5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e649106e4e74bc5b2597ce24a3121d7",
            "placeholder": "​",
            "style": "IPY_MODEL_355e898469d646758956dc817bd3b48c",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "c8b1e0d2a5af4314813c7bf60e68945a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f07a1844e2504f4c86694219fc2803d8",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5d81838ae414a5fb5ff402fb51b8a7d",
            "value": 5069051
          }
        },
        "d539deca225d47a0aaaff4ec03acfba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e3d3cf80a2b4e78a7ec6eea743e55d9",
            "placeholder": "​",
            "style": "IPY_MODEL_ae1580be847849d5bf233753255c5d60",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 13.5MB/s]"
          }
        },
        "857fdaf6c88b48bdade3bef37cdfd93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e649106e4e74bc5b2597ce24a3121d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355e898469d646758956dc817bd3b48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f07a1844e2504f4c86694219fc2803d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5d81838ae414a5fb5ff402fb51b8a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e3d3cf80a2b4e78a7ec6eea743e55d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae1580be847849d5bf233753255c5d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f6c40f94fca4ae980e0923502033058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86a2fe7fcdc74c28b36593b2c6dabf1b",
              "IPY_MODEL_0d6fc4428ea04978ada39f2da16c5a55",
              "IPY_MODEL_5c015956be764fb5902dbfe7a4d27d6c"
            ],
            "layout": "IPY_MODEL_11f9d3de11da4b38845b06710eaada0f"
          }
        },
        "86a2fe7fcdc74c28b36593b2c6dabf1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cf6b7a5604d4f33afbfd44266179bc9",
            "placeholder": "​",
            "style": "IPY_MODEL_11fb9e8e726146658e192e4214a916e0",
            "value": "tokenizer.json: 100%"
          }
        },
        "0d6fc4428ea04978ada39f2da16c5a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a08ec21c6474a05ba182c5f5065f693",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c7252fdc0224ca9aef92cf3d66cdee9",
            "value": 9096718
          }
        },
        "5c015956be764fb5902dbfe7a4d27d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3bac57d47d9464b8e58b193f345cb60",
            "placeholder": "​",
            "style": "IPY_MODEL_b8fd9ec7c49c47e1820d44c473ab51d0",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 26.8MB/s]"
          }
        },
        "11f9d3de11da4b38845b06710eaada0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cf6b7a5604d4f33afbfd44266179bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11fb9e8e726146658e192e4214a916e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a08ec21c6474a05ba182c5f5065f693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c7252fdc0224ca9aef92cf3d66cdee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3bac57d47d9464b8e58b193f345cb60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8fd9ec7c49c47e1820d44c473ab51d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}